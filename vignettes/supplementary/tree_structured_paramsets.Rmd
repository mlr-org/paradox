---
title: "Tree structured ParamSets"
output:
  html_document:
    toc: true
    toc_float:
      collapsed: true
      smooth_scroll: false
    dev: svg
vignette: >
  %\VignetteIndexEntry{Tree structured ParamSets}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE, cache = FALSE}
library(phng)
set.seed(123)
knitr::opts_chunk$set(cache = TRUE, collapse = FALSE, dev = "svg", fig.height = 3.5)
knitr::knit_hooks$set(document = function(x){
  gsub("```\n*```r*\n*", "", x)
})
```

# ParamSetTree 

## Setup
Install the Tree branch
```{r eval = FALSE}
devtools::install_github("mlr-org/phng", ref = "tree")
```
This tutorial will guide you how to set up conditional hyperparameters for SVM and Random Forest, setting up Machine Learning Pipeline and Deep Learning Architecture 

## Support Vector Machine/Random Forest Model Multiplexer Hyper-parameter Specification
Some hyper-parameters could depend on other hyper-parameters. For example, if we have a model multiplexer of Support Vector Machine(SVM) and Random Forest(RF). The hyper-parameter "kernel" only makes sense if the chosen model is "SVM". Moreover, the hyper-parameter of "gamma" only makes sense if the chosen kernel for "SVM" is "rbf". This kind of relationship resembles a tree or directed graph structure where a node is only activated when its corresponding parent node is activated. 

To tackle the above mentioned problem, we have the following code. Each separate hyper-parameter has a unique identifier called "id" which is defined inside the ParamSimple(ParamCategorical, ParamReal, ..etc). These "id"s are extracted from ParamSimple and used as the unique identifier as the node in the tree as well.

```{r example1}
   library(phng)
   pst = ParamSetTree$new("test",
       ParamCategorical$new(id = "model", values = c("SVM", "RF")),
       addDep(ParamReal$new(id = "C", lower = 0, upper = 100), 
         did = "model", expr = quote(model == "SVM")), # did here means dependant id
       addDep(ParamCategorical$new(id = "kernel", values = c("rbf", "poly")), 
         did = "model", expr = quote(model == "SVM")),
       addDep(ParamReal$new(id = "gamma", lower = 0, upper = 101), 
         did = "kernel", expr = quote(kernel == "rbf")),
       addDep(ParamInt$new(id = "n", lower = 1L, upper = 10L), 
         did = "kernel", expr = quote(kernel == "poly")),
       addDep(ParamInt$new(id = "n_tree", lower = 1L, upper = 10L), 
         did = "model", expr = quote(model == "RF"))
       )
   pst$sample(1L)
   pst$sampleList()
   pst$toStringVal()
   pst$sample(10L)
```


## Machine learning pipeline specification 
```{r ml}
   pst = ParamSetTree$new("pre",     
     ParamCategorical$new(id = "preprocessing", values = c("PCA", "FeatureFiltering")),
      addDep(ParamInt$new(id = "pca.k", lower = 1, upper = 5), 
        did = "preprocessing", expr = quote(preprocessing == "PCA")),
       addDep(ParamInt$new(id = "filter.n", lower = 1, upper = 10), 
         did = "preprocessing", expr = quote(preprocessing == "FeatureFiltering")))

   pst1 = ParamSetTree$new("ml",
       ParamCategorical$new(id = "model", values = c("SVM", "RF")),
       addDep(ParamReal$new(id = "C", lower = 0, upper = 100), 
         did = "model", expr = quote(model == "SVM")), # did here means dependant id
       addDep(ParamCategorical$new(id = "kernel", values = c("rbf", "poly")), 
         did = "model", expr = quote(model == "SVM")),
       addDep(ParamReal$new(id = "gamma", lower = 0, upper = 101), 
         did = "kernel", expr = quote(kernel == "rbf")),
       addDep(ParamInt$new(id = "poly.n", lower = 1L, upper = 10L), 
         did = "kernel", expr = quote(kernel == "poly")),
       addDep(ParamInt$new(id = "n_tree", lower = 1L, upper = 10L), 
         did = "model", expr = quote(model == "RF"))
       )
   pst$setChild(pst1)
   pst$sample(4L)
   pst$toStringVal()  # always keep the last sampled value
```

## Neural network architecture specification
Multiple Layers
```{r nn}
  ps = ParamSetTreeRe$new("nn", nr = 2,
      ParamInt$new(id = "layer_dense.units", lower = 2L, upper = 1000L),
      ParamReal$new(id = "kernel_regularizer", lower = 0, upper = 3.0), 
      ParamReal$new(id = "bias_regularizer", lower = 0, upper = 3.0), 
      ParamCategorical$new(id = "reg_type", values = c("regularizer_l1", "regularizer_l2")),
      ParamCategorical$new(id = "activation_fun", values = c("sigmoid", "tanh", "linear")))
  ps$sample(3L)
``` 

```{r keras, eval = FALSE}
library(keras)
ps$sample()
list.par.val = ps$sampleList(flat = FALSE)
tex = keras_helper(input.shape = 256, output.shape = 10L, 
  output.act = "softmax", loss = "mse", 
  lr = 0.0025, list.par.val = list.par.val)
eval(parse(text = tex))
```
